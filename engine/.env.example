# AnimaForge Engine Environment Configuration

# Ollama Configuration (for local LLM)
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=codellama

# Google Gemini Configuration
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-pro

# Anthropic Claude Configuration
ANTHROPIC_API_KEY=your_anthropic_api_key_here
CLAUDE_MODEL=claude-3-5-sonnet-20241022

# Default Settings
DEFAULT_LLM_BACKEND=ollama
DEFAULT_QUALITY=medium
DEFAULT_OUTPUT_PATH=/tmp/animaforge_output
